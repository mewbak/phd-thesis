\chapter{Introduction}\label{sec:ba}

%The problem you want to tackle
Analyzing binary code is crucial in software engineering and security research.
Some of the notable applications of binary analysis can be found in binary
instrumentation
(\cite{Bruening:CGO2003,PEBIL10,Pin:2005,Valgrind:ENTCS03,DynamoRIO:2004}),
  binary translation~\cite{UQBT:2000}, software hardening
  (\cite{Cha:2015,Ford:2008,Zhang,Zhang:2013}), software testing
  (\cite{Chipounov:2011,Avgerinos:2014,godefroid_automated_2008}), CPU
  emulation (\cite{QEMU:USENIX05,Magnusson:2002}), malware detection
  (\cite{Christodorescu:2005,Kruegel:2004,BitBlaze:2008,BAP:CAV11,Egele:USENIX07,Yin:CCS07}),
  automated reverse engineering
  (\cite{Cui:2008,Lin:2008,Schwartz:2013,Yakdan2015NDSS,McSema:Recon14,Angr,Radare2}),
  sand-boxing~\cite{Kiriansky:2002:SEV,Erlingsson:2006,Yee:2009},
  profiling~\cite{Harris:2005,Srivastava:1994}, and automatic exploit
  generation~\cite{Cha:2012}.
               
                 Binary analysis is generally performed by various decompiler
                 projects
                 ~\cite{McSema:Recon14,Remill,Angr1,BAP:CAV11,Radare2}, whose
                 very first step is to translate the machine code to an
                 intermediate representation (IR), and thereby exposing many
                 high-level properties (like control flow, function boundary
                     and prototype, variable and their type etc.) of the
                 binary, which  assist further analysis and/or optimization.
                 Formally establishing faithfulness of the decompilation (i.e.
                     translation from machine code to high level IR) is pivotal
                 to gain trust in any binary analysis. Any bug in the
                 translation would invalidate the binary analysis results.  For
                 example, a malware analysis system might miss vulnerabilities
                 or a binary instrumentation system, instrumenting a buggy IR,
                 might lead to failure or even crash in interpreting the
                 instrumented program. Therefore, automatic validation tools
                 are needed urgently to uncover hidden problems in a binary
                 translator. 

% What is the current state of the art and why that is insufficient
Despite of the importance in establishing the faithfulness of the binary
translators, there has been surprisingly little effort towards that direction.
The most notable approaches are either based on hardware co-simulation
testing~\cite{Martignoni:ISSTA2009,Martignoni:ISSTA2010}, which is limited
because generating specific test-cases to uncover semantic bugs in a lifter is
non-trivial, or differential-testing~\cite{Martignoni:ASPLOS2012,ASE2017},
  which is limited in terms of coverage of the instructions validated and
  faithfulness guarantees it provides (Refer to
      Chapter~\ref{sec:related-work}). 

%How you plan to improve on the state of the art Given the importance  in
%establishing the faithfulness of binary lifter (or translator), 
We propose to employ \tv on binary lifters, as a means to establish the
faithfulness of the translation, by leveraging the semantics of the languages
involved (e.g. the Intel's X86-64 and the high-level IR).  Given the recent
advances in translation validation~\cite{Pnueli:1998} in validating
compilation~\cite{Necula:2000,Pnueli:1998,Stepp:2011,Tristan:2011,VOC2002,TVOC:CAV2005},
  employing \tv to validate binary translators seems a promising direction to
  explore,
%Given the recent advances in translation validation~\cite{Pnueli:1998} in
%validating
%compilation~\cite{Necula:2000,Pnueli:1998,Stepp:2011,Tristan:2011,VOC2002,TVOC:CAV2005},
  %a basic version of this strategy is likely quite feasible today,
  however, there are additional challenges to deal with when it comes to
  validating the decompilation pipeline (Refer Section~\ref{sec:challenges}).
  Moreover, we would like validation approach to be general enough and hence
  applicable to any state-of-the-art binary to high-level IR
  translators~\cite{McSema:Recon14,Remill,FCD,llvm-mctoll,BAP:CAV11,Angr1,DiFederico:CC2017}.
  The idea is to validate the translators without leveraging any knowledge of
  the translation involved, which in turn makes the problem even more
  challenging (Refer Chapter~\ref{sec:future}).
  %thereby avoiding any translator specific customization during validation
  %(Refer Chapter~\ref{sec:future}).  However, having this goal makes the
  %problem even more challenging.

We believe that formally validating the translation is more robust as compared
to (1) validating the translation using random (or low coverage) test-cases,
   and (2) differential testing technique which tests the correctness of a
   translation, generated by a translator, by comparing its behaviors with that
   provided by other translators under test. \cmt{This means, declaring a
     translation to be correct assumes the correctness of all the translator.}

%Summarize your contributions
\paragraph{Contributions}
Below we propose the  primary contributions of our work.

\textbf{\emph{Most Complete user-level \ISA Semantics:}} Towards the goals of
\tv of binary translators, we developed\cite{DasguptaAdve:PLDI19} the most
complete and thoroughly tested formal semantics of \ISA to date, which
faithfully formalizes all the non-deprecated, sequential user-level
instructions of the x86-64 Haswell instruction set architecture. 

\textbf{\emph{Translation validation on binary translators~}} We propose tools
and techniques to formally validate the translation from binary to high level
IR.  To the best of our knowledge, we are the first to propose \tv to establish
the faithfulness of binary lifters targeting LLVM as their high-level IR. We
would demonstrate the applicability of our approach by validating the
translation of a realistic decompiler, McSema~\cite{McSema:Recon14}.
%and revng~\cite{DiFederico:CC2017}}.

\textbf{\emph{Automated back-box approaches to \tv~}} We would like our
technique to work automatically and uniformly across translators considering
the translators as black-boxes, i.e. without using any translator-generated
hints  or translator-specific heuristics to assist the validation. We would
like to demonstrate the effectiveness  of our solution by validating against
two or more decompilers.  Optionally, we would like to use machine learning
techniques to infer the  variable or basic block correspondence between binary
and LLVM IR code which will help in realizing a translator-agnostic approach to
\tv.

%\textbf{\emph{Translator-agnostic solution~}}     

%In the next section, we elaborate on our motivation to establish faithfulness
%of binary translators.  Why it is important \section{Benefits of Binary
  %Analysis}
